{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Appendix A -- Advanced NumPy</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rc('figure', figsize=(10, 6))\n",
    "PREVIOUS_MAX_ROWS = pd.options.display.max_rows\n",
    "pd.options.display.max_columns = 20\n",
    "pd.options.display.max_rows = 20\n",
    "pd.options.display.max_colwidth = 80\n",
    "np.set_printoptions(precision=4, suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>In this appendix, I will go deeper into the NumPy library for array computing. This will include more internal details about the ndarray type and more advanced array manipulations and algorithms.</p>\n",
    "\n",
    "<p>This appendix contains miscellaneous topics and does not necessarily need to be read linearly. Throughout the chapters, I will generate random data for many examples that will use the default random number generator in the <code>numpy.random</code> module:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(seed=12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>A.1 ndarray Object Internals</h2>\n",
    "\n",
    "<p>The NumPy ndarray provides a way to interpret a block of homogeneously typed data (either contiguous or strided) as a multidimensional array object. The data type, or <em>dtype</em>, determines how the data is interpreted as being floating point, integer, Boolean, or any of the other types we’ve been looking at.</p>\n",
    "\n",
    "<p>Part of what makes ndarray flexible is that every array object is a strided view on a block of data. You might wonder, for example, how the array view <code>arr[::2, ::-1]</code> does not copy any data. The reason is that the ndarray is more than just a chunk of memory and a data type; it also has <em>striding</em> information that enables the array to move through memory with varying step sizes. More precisely, the ndarray internally consists of the following:</p>\n",
    "<ul>\n",
    "    <li>A <em>pointer to data</em>—that is, a block of data in RAM or in a memory-mapped file</li>\n",
    "    <li>The <em>data type</em> or dtype describing fixed-size value cells in the array</li>\n",
    "    <li>A tuple indicating the array’s <em>shape</em></li>\n",
    "    <li>A tuple of strides—integers indicating the number of bytes to “step” in order to advance one element along a dimension</li>\n",
    "</ul>\n",
    "<p>See <a href=\"#numpy_ndarray\">Fig. A.1: The NumPy ndarray object </a> for a simple mock-up of the ndarray innards.</p>\n",
    "<figure id='numpy_ndarray'>\n",
    "    <img src=\"images/pda3_a001.png\">\n",
    "    <figcaption>Fig. A.1: The NumPy ndarray object</figcaption>\n",
    "</figure>\n",
    "<p>For example, a 10 × 5 array would have the shape <code>(10, 5)</code>:</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 5)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ones((10, 5)).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>A typical (C order) 3 × 4 × 5 array of <code>float64</code> (8-byte) values has the strides <code>(160, 40, 8)</code> (knowing about the strides can be useful because, in general, the larger the strides on a particular axis, the more costly it is to perform computation along that axis):</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160, 40, 8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ones((3, 4, 5), dtype=np.float64).strides"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>While it is rare that a typical NumPy user would be interested in the array strides, they are needed to construct \"zero-copy\" array views. Strides can even be negative, which enables an array to move \"backward\" through memory (this would be the case, for example, in a slice like <code>obj[::-1]</code> or <code>obj[:, ::-1]</code>).</p>\n",
    "\n",
    "<h2>NumPy Data Type Hierarchy</h2>\n",
    "\n",
    "<p>You may occasionally have code that needs to check whether an array contains integers, floating-point numbers, strings, or Python objects. Because there are multiple types of floating-point numbers (<code>float16</code> through <code>float128</code>), checking that the data type is among a list of types would be very verbose. Fortunately, the data types have superclasses, such as <code>np.integer</code> and <code>np.floating</code>, which can be used with the <code>np.issubdtype</code> function:</p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ints = np.ones(10, dtype=np.uint16)\n",
    "floats = np.ones(10, dtype=np.float32)\n",
    "np.issubdtype(ints.dtype, np.integer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.issubdtype(floats.dtype, np.floating)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>You can see all of the parent classes of a specific data type by calling the type’s <code>mro</code> method:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[numpy.float64,\n",
       " numpy.floating,\n",
       " numpy.inexact,\n",
       " numpy.number,\n",
       " numpy.generic,\n",
       " float,\n",
       " object]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.float64.mro()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Therefore, we also have:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.issubdtype(ints.dtype, np.number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Most NumPy users will never have to know about this, but it is occasionally useful. See <a href='#numpy_data_type'>Fig. A.2: The NumPy data type class hierarchy</a> for a graph of the data type hierarchy and parent–subclass relationships.</p>\n",
    "<figure id='numpy_data_type'>\n",
    "    <img src=\"images/pda3_a002.png\">\n",
    "    <figcaption>Fig. A.2: The NumPy data type class hierarchy</figcaption>\n",
    "</figure>\n",
    "\n",
    "<h2>A.2 Advanced Array Manipulation</h2>\n",
    "\n",
    "<p>There are many ways to work with arrays beyond fancy indexing, slicing, and Boolean subsetting. While much of the heavy lifting for data analysis applications is handled by higher-level functions in pandas, you may at some point need to write a data algorithm that is not found in one of the existing libraries.</p>\n",
    "\n",
    "<h3>Reshaping Arrays</h3>\n",
    "\n",
    "<p>In many cases, you can convert an array from one shape to another without copying any data. To do this, pass a tuple indicating the new shape to the <code>reshape</code> array instance method. For example, suppose we had a one-dimensional array of values that we wished to rearrange into a matrix (this is illustrated in <a href=\"#reshaping\">Fig. A.3: Reshaping in C (row major) or FORTRAN (column major) order</a>):</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = np.arange(8)\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [2, 3],\n",
       "       [4, 5],\n",
       "       [6, 7]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr.reshape((4, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure id='reshaping'>\n",
    "    <img src=\"images/pda3_a003.png\">\n",
    "    <figcaption>Fig. A.3: Reshaping in C (row major) or FORTRAN (column major> order</figcaption>\n",
    "</figure>\n",
    "<p>A multidimensional array can also be reshaped:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2, 3],\n",
       "       [4, 5, 6, 7]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr.reshape((4, 2)).reshape((2, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>One of the passed shape dimensions can be –1, in which case the value used for that dimension will be inferred from the data:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2],\n",
       "       [ 3,  4,  5],\n",
       "       [ 6,  7,  8],\n",
       "       [ 9, 10, 11],\n",
       "       [12, 13, 14]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = np.arange(15)\n",
    "arr.reshape((5, -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Since an array’s <code>shape</code> attribute is a tuple, it can be passed to <code>reshape</code>, too:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 5)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "other_arr = np.ones((3, 5))\n",
    "other_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3,  4],\n",
       "       [ 5,  6,  7,  8,  9],\n",
       "       [10, 11, 12, 13, 14]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr.reshape(other_arr.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>The opposite operation of <code>reshape</code> from one-dimensional to a higher dimension is typically known as <em>flattening</em> or <em>raveling</em>:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2],\n",
       "       [ 3,  4,  5],\n",
       "       [ 6,  7,  8],\n",
       "       [ 9, 10, 11],\n",
       "       [12, 13, 14]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = np.arange(15).reshape((5, 3))\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><code>ravel</code> does not produce a copy of the underlying values if the values in the result were contiguous in the original array.</p>\n",
    "\n",
    "<p>The <code>flatten</code> method behaves like <code>ravel</code> except it always returns a copy of the data:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>The data can be reshaped or raveled in different orders. This is a slightly nuanced topic for new NumPy users and is therefore the next subtopic.</p>\n",
    "\n",
    "<h3>C Versus FORTRAN Order</h3>\n",
    "\n",
    "<p>NumPy is able to adapt to many different layouts of your data in memory. By default, NumPy arrays are created in <em>row major</em> order. Spatially this means that if you have a two-dimensional array of data, the items in each row of the array are stored in adjacent memory locations. The alternative to row major ordering is <em>column major</em> order, which means that values within each column of data are stored in adjacent memory locations.</p>\n",
    "\n",
    "<p>For historical reasons, row and column major order are also known as C and FORTRAN order, respectively. In the FORTRAN 77 language, matrices are all column major.</p>\n",
    "\n",
    "<p>Functions like <code>reshape</code> and <code>ravel</code> accept an order argument indicating the order to use the data in the array. This is usually set to <code>'C'</code> or <code>'F'</code> in most cases (there are also less commonly used options <code>'A'</code> and <code>'K'</code>; see the NumPy documentation, and refer back to <a href='#reshaping'>Fig. A.3: Reshaping in C (row major) or FORTRAN (column major) order for an illustration of these options</a>):</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3],\n",
       "       [ 4,  5,  6,  7],\n",
       "       [ 8,  9, 10, 11]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = np.arange(12).reshape((3, 4))\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  4,  8,  1,  5,  9,  2,  6, 10,  3,  7, 11])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr.ravel('F')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Reshaping arrays with more than two dimensions can be a bit mind-bending (see <a href='#reshaping'>Reshaping in C (row major) or FORTRAN (column major) order</a>). The key difference between C and FORTRAN order is the way in which the dimensions are walked:</p>\n",
    "<dl>\n",
    "    <dt>C/row major order</dt>\n",
    "    <dd>Traverse higher dimensions first (e.g., axis 1 before advancing on axis 0).</dd>\n",
    "    <dt>FORTRAN/column major order</dt>\n",
    "    <dd>Traverse higher dimensions last (e.g., axis 0 before advancing on axis 1).</dd>\n",
    "</dl>\n",
    "\n",
    "<h3>Concatenating and Splitting Arrays</h3>\n",
    "\n",
    "<p><code>numpy.concatenate</code> takes a sequence (tuple, list, etc.) of arrays and joins them in order along the input axis:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  2,  3],\n",
       "       [ 4,  5,  6],\n",
       "       [ 7,  8,  9],\n",
       "       [10, 11, 12]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr1 = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "arr2 = np.array([[7, 8, 9], [10, 11, 12]])\n",
    "np.concatenate([arr1, arr2], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  2,  3,  7,  8,  9],\n",
       "       [ 4,  5,  6, 10, 11, 12]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate([arr1, arr2], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>There are some convenience functions, like <code>vstack</code> and <code>hstack</code>, for common kinds of concatenation. The preceding operations could have been expressed as:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  2,  3],\n",
       "       [ 4,  5,  6],\n",
       "       [ 7,  8,  9],\n",
       "       [10, 11, 12]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.vstack((arr1, arr2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  2,  3,  7,  8,  9],\n",
       "       [ 4,  5,  6, 10, 11, 12]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.hstack((arr1, arr2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><code>split</code>, on the other hand, slices an array into multiple arrays along an axis:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.4238,  1.2637],\n",
       "       [-0.8707, -0.2592],\n",
       "       [-0.0753, -0.7409],\n",
       "       [-1.3678,  0.6489],\n",
       "       [ 0.3611, -1.9529]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = rng.standard_normal((5, 2))\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.4238,  1.2637]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first, second, third = np.split(arr, [1, 3])\n",
    "first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.8707, -0.2592],\n",
       "       [-0.0753, -0.7409]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.3678,  0.6489],\n",
       "       [ 0.3611, -1.9529]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "third"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>The value <code>[1, 3]</code> passed to <code>np.split</code> indicates the indices at which to split the array into pieces.</p>\n",
    "\n",
    "<p>See <a href='#array_concatenation'>Array concatenation functions</a> for a list of all relevant concatenation and splitting functions, some of which are provided only as a convenience of the very general-purpose <code>concatenate</code>.</p>\n",
    "<table id='array_concatenation'>\n",
    "    <caption>Table A.1: Array concatenation functions</caption>\n",
    "    <tr>\n",
    "        <th>Function</th>\n",
    "        <th>Description</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><code>concatenate</code></td>\n",
    "        <td>Most general function, concatenate collection of arrays along one axis</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><code>vstack</code>, <code>row_stack</code></td>\n",
    "        <td>Stack arrays by rows (along axis 0)</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><code>hstack</code></td>\n",
    "        <td>Stack arrays by columns (along axis 1)</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><code>column_stack</code></td>\n",
    "        <td>Like <code>hstack</code>, but convert 1D arrays to 2D column vectors first</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><code>dstack</code></td>\n",
    "        <td>Stack arrays by “depth” (along axis 2)</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><code>split</code></td>\n",
    "        <td>Split array at passed locations along a particular axis</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><code>hsplit/vsplit</code></td>\n",
    "        <td>Convenience functions for splitting on axis 0 and 1, respectively</td>\n",
    "    </tr>\n",
    "</table>\n",
    "    \n",
    "<h4>Stacking helpers: <code>r_</code> and <code>c_</code></h4>\n",
    "\n",
    "<p>There are two special objects in the NumPy namespace, <code>r_</code> and <code>c_</code>, that make stacking arrays more concise:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.    ,  1.    ],\n",
       "       [ 2.    ,  3.    ],\n",
       "       [ 4.    ,  5.    ],\n",
       "       [ 2.3474,  0.9685],\n",
       "       [-0.7594,  0.9022],\n",
       "       [-0.467 , -0.0607]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = np.arange(6)\n",
    "arr1 = arr.reshape((3, 2))\n",
    "arr2 = rng.standard_normal((3, 2))\n",
    "np.r_[arr1, arr2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.    ,  1.    ,  0.    ],\n",
       "       [ 2.    ,  3.    ,  1.    ],\n",
       "       [ 4.    ,  5.    ,  2.    ],\n",
       "       [ 2.3474,  0.9685,  3.    ],\n",
       "       [-0.7594,  0.9022,  4.    ],\n",
       "       [-0.467 , -0.0607,  5.    ]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.c_[np.r_[arr1, arr2], arr]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>These additionally can translate slices to arrays:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1, -10],\n",
       "       [  2,  -9],\n",
       "       [  3,  -8],\n",
       "       [  4,  -7],\n",
       "       [  5,  -6]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.c_[1:6, -10:-5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>See the docstring for more on what you can do with <code>c_</code> and <code>r_</code>.</p>\n",
    "\n",
    "<h3>Repeating Elements: <code>tile</code> and <code>repeat</code></h3>\n",
    "\n",
    "<p>Two useful tools for repeating or replicating arrays to produce larger arrays are the <code>repeat</code> and <code>tile</code> functions. repeat replicates each element in an array some number of times, producing a larger array:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = np.arange(3)\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 1, 1, 2, 2, 2])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr.repeat(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><strong>Note</strong><br />\n",
    "    The need to replicate or repeat arrays can be less common with NumPy than it is with other array programming frameworks like MATLAB. One reason for this is that <em>broadcasting</em> often fills this need better, which is the subject of the next section.</p>\n",
    "\n",
    "<p>By default, if you pass an integer, each element will be repeated that number of times. If you pass an array of integers, each element can be repeated a different number of times:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1, 1, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr.repeat([2, 3, 4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Multidimensional arrays can have their elements repeated along a particular axis:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.7888, -1.2567],\n",
       "       [ 0.5759,  1.399 ]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = rng.standard_normal((2, 2))\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.7888, -1.2567],\n",
       "       [ 0.7888, -1.2567],\n",
       "       [ 0.5759,  1.399 ],\n",
       "       [ 0.5759,  1.399 ]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr.repeat(2, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.7888, -1.2567],\n",
       "       [ 0.7888, -1.2567],\n",
       "       [ 0.5759,  1.399 ],\n",
       "       [ 0.5759,  1.399 ],\n",
       "       [ 0.5759,  1.399 ]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr.repeat([2, 3], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.7888,  0.7888, -1.2567, -1.2567, -1.2567],\n",
       "       [ 0.5759,  0.5759,  1.399 ,  1.399 ,  1.399 ]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr.repeat([2, 3], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><code>tile</code>, on the other hand, is a shortcut for stacking copies of an array along an axis. Visually you can think of it as being akin to “laying down tiles”:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.7888, -1.2567],\n",
       "       [ 0.5759,  1.399 ]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.7888, -1.2567,  0.7888, -1.2567],\n",
       "       [ 0.5759,  1.399 ,  0.5759,  1.399 ]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.tile(arr, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>The second argument is the number of tiles; with a scalar, the tiling is made row by row, rather than column by column. The second argument to <code>tile</code> can be a tuple indicating the layout of the “tiling”:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.7888, -1.2567],\n",
       "       [ 0.5759,  1.399 ]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.7888, -1.2567],\n",
       "       [ 0.5759,  1.399 ],\n",
       "       [ 0.7888, -1.2567],\n",
       "       [ 0.5759,  1.399 ]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.tile(arr, (2, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.7888, -1.2567,  0.7888, -1.2567],\n",
       "       [ 0.5759,  1.399 ,  0.5759,  1.399 ],\n",
       "       [ 0.7888, -1.2567,  0.7888, -1.2567],\n",
       "       [ 0.5759,  1.399 ,  0.5759,  1.399 ],\n",
       "       [ 0.7888, -1.2567,  0.7888, -1.2567],\n",
       "       [ 0.5759,  1.399 ,  0.5759,  1.399 ]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.tile(arr, (3, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Fancy Indexing Equivalents: take and put</h3>\n",
    "\n",
    "<p>As you may recall from Ch 4: NumPy Basics: Arrays and Vectorized Computation, one way to get and set subsets of arrays is by <em>fancy</em> indexing using integer arrays:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([700, 100, 200, 600])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = np.arange(10) * 100\n",
    "inds = [7, 1, 2, 6]\n",
    "arr[inds]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>There are alternative ndarray methods that are useful in the special case of making a selection only on a single axis:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([700, 100, 200, 600])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr.take(inds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,  42,  42, 300, 400, 500,  42,  42, 800, 900])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr.put(inds, 42)\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,  41,  42, 300, 400, 500,  43,  40, 800, 900])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr.put(inds, [40, 41, 42, 43])\n",
    "arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>To use <code>take</code> along other axes, you can pass the <code>axis</code> keyword:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.3223, -0.2997,  0.9029, -1.6216],\n",
       "       [-0.1582,  0.4495, -1.3436, -0.0817]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inds = [2, 0, 2, 1]\n",
    "arr = rng.standard_normal((2, 4))\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.9029,  1.3223,  0.9029, -0.2997],\n",
       "       [-1.3436, -0.1582, -1.3436,  0.4495]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr.take(inds, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><code>put</code> does not accept an axis argument but rather indexes into the flattened (one-dimensional, C order) version of the array. Thus, when you need to set elements using an index array on other axes, it is best to use <code>[]</code>-based indexing.</p>\n",
    "\n",
    "<h2>A.3 Broadcasting</h2>\n",
    "\n",
    "<p>Broadcasting governs how operations work between arrays of different shapes. It can be a powerful feature, but it can cause confusion, even for experienced users. The simplest example of broadcasting occurs when combining a scalar value with an array:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = np.arange(5)\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  4,  8, 12, 16])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr * 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Here we say that the scalar value 4 has been <em>broadcast</em> to all of the other elements in the multiplication operation.</p>\n",
    "\n",
    "<p>For example, we can demean each column of an array by subtracting the column means. In this case, it is necessary only to subtract an array containing the mean of each column:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.1206, 0.243 , 0.1444])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = rng.standard_normal((4, 3))\n",
    "arr.mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.6042,  2.3751,  0.633 ],\n",
       "       [ 0.7081, -1.202 , -1.3538],\n",
       "       [-1.5329,  0.2985,  0.6076],\n",
       "       [-0.7793, -1.4717,  0.1132]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demeaned = arr - arr.mean(0)\n",
    "demeaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0., -0.,  0.])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demeaned.mean(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>See <a href='#broadcasting'>Fig. A.4: Broadcasting over axis 0 with a 1D array</a> for an illustration of this operation. Demeaning the rows as a broadcast operation requires a bit more care. Fortunately, broadcasting potentially lower dimensional values across any dimension of an array (like subtracting the row means from each column of a two-dimensional array) is possible as long as you follow the rules.</p>\n",
    "\n",
    "<p>This brings us to the broadcasting rule.</p>\n",
    "\n",
    "<p>Two arrays are compatible for broadcasting if for each <em>trailing dimension</em> (i.e., starting from the end) the axis lengths match or if either of the lengths is 1. Broadcasting is then performed over the missing or length 1 dimensions.</p>\n",
    "<figure id='broadcasting'>\n",
    "    <img src=\"images/pda3_a004.png\">\n",
    "    <figcaption>Fig. A.4: Broadcasting over axis 0 with a 1D array</figcaption>\n",
    "</figure>\n",
    "<p>Even as an experienced NumPy user, I often find myself having to pause and draw a diagram as I think about the broadcasting rule. Consider the last example and suppose we wished instead to subtract the mean value from each row. Since <code>arr.mean(0)</code> has length 3, it is compatible for broadcasting across axis 0 because the trailing dimension in <code>arr</code> is 3 and therefore matches. According to the rules, to subtract over axis 1 (i.e., subtract the row mean from each row), the smaller array must have the shape <code>(4, 1)</code>:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.7247,  2.6182,  0.7774],\n",
       "       [ 0.8286, -0.959 , -1.2094],\n",
       "       [-1.4123,  0.5415,  0.7519],\n",
       "       [-0.6588, -1.2287,  0.2576]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_means = arr.mean(1)\n",
    "row_means.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.7068],\n",
       "       [-0.4466],\n",
       "       [-0.0396],\n",
       "       [-0.5433]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_means.reshape((4, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demeaned = arr - row_means.reshape((4, 1))\n",
    "demeaned.mean(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>See <a href='#broadcasting_axis_1'>Fig. A.5: Broadcasting over axis 1 of a 2D array</a> for an illustration of this operation.</p>\n",
    "<figure id='broadcasting_axis_1'>\n",
    "    <img src='images/pda3_a005.png'>\n",
    "    <figcaption>Fig. A.5: Broadcasting over axis 1 of a 2D array</figcaption>\n",
    "</figure>\n",
    "    \n",
    "\n",
    "<p>See <a href='#broadcasting_axis_0'>Fig. A.6: Broadcasting over axis 0 of a 3D array</a> for another illustration, this time adding a two-dimensional array to a three-dimensional one across axis 0.</p>\n",
    "<figure id='broadcasting_axis_0'>\n",
    "    <img src=\"images/pda3_a006.png\">\n",
    "    <figcaption>Fig. A.6: Broadcasting over axis 0 with of a 3D array</figcaption>\n",
    "</figure>\n",
    "\n",
    "<h3>Broadcasting over Other Axes</h3>\n",
    "\n",
    "<p>Broadcasting with higher dimensional arrays can seem even more mind-bending, but it is really a matter of following the rules. If you don’t, you’ll get an error like this:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (4,3) (4,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[59], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43marr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43marr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (4,3) (4,) "
     ]
    }
   ],
   "source": [
    "arr - arr.mean(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>It’s quite common to want to perform an arithmetic operation with a lower dimensional array across axes other than axis 0. According to the broadcasting rule, the “broadcast dimensions” must be 1 in the smaller array. In the example of row demeaning shown here, this means reshaping the row to be shape <code>(4, 1)</code> instead of <code>(4,)</code>:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.018 ,  0.9114, -0.9294],\n",
       "       [ 1.2752, -0.5124, -0.7628],\n",
       "       [-1.3727,  0.5811,  0.7915],\n",
       "       [-0.1155, -0.6854,  0.8009]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr - arr.mean(1).reshape((4, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>In the three-dimensional case, broadcasting over any of the three dimensions is only a matter of reshaping the data to be shape compatible. <a href='#compatible'>Fig. A.7: Compatible 2D array shapes for broadcasting over a 3D array</a> nicely visualizes the shapes required to broadcast over each axis of a three-dimensional array.</p>\n",
    "<figure id='compatible'>\n",
    "    <img src=\"images/pda3_a007.png\">\n",
    "    <figcaption>Fig. A.7:Compatible 2D array shapes for broadcasting over a 3D array</figcaption>\n",
    "</figure>\n",
    "<p>A common problem, therefore, is needing to add a new axis with length 1 specifically for broadcasting purposes. Using <code>reshape</code> is one option, but inserting an axis requires constructing a tuple indicating the new shape. This often can be a tedious exercise. Thus, NumPy arrays offer a special syntax for inserting new axes by indexing. We use the special <code>np.newaxis</code> attribute along with “full” slices to insert the new axis:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 1, 4)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = np.zeros((4, 4))\n",
    "arr_3d = arr[:, np.newaxis, :]\n",
    "arr_3d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.3129],\n",
       "       [-0.1308],\n",
       "       [ 1.27  ]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_1d = rng.standard_normal(3)\n",
    "arr_1d[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.3129, -0.1308,  1.27  ]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_1d[np.newaxis, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Thus, if we had a three-dimensional array and wanted to demean axis 2, we would need to write:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = rng.standard_normal((3, 4, 5))\n",
    "depth_means = arr.mean(2)\n",
    "depth_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_means.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "demeaned = arr - depth_means[:, :, np.newaxis]\n",
    "demeaned.mean(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>You might be wondering if there’s a way to generalize demeaning over an axis without sacrificing performance. There is, but it requires some indexing gymnastics:</p>\n",
    "<pre>\n",
    "def demean_axis(arr, axis=0):\n",
    "    means = arr.mean(axis)\n",
    "\n",
    "    # This generalizes things like [:, :, np.newaxis] to N dimensions\n",
    "    indexer = [slice(None)] * arr.ndim\n",
    "    indexer[axis] = np.newaxis\n",
    "    return arr - means[indexer]\n",
    "</pre>\n",
    "<h3>Setting Array values by Broadcasting</h3>\n",
    "<p>The same broadcasting rule governing arithmetic operations also applies to setting values via array indexing. In a simple case, we can do things like:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.zeros((4, 3))\n",
    "arr[:] = 5\n",
    "arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>However, if we had a one-dimensional array of values we wanted to set into the columns of the array, we can do that as long as the shape is compatible:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = np.array([1.28, -0.42, 0.44, 1.6])\n",
    "arr[:] = col[:, np.newaxis]\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr[:2] = [[-1.37], [0.509]]\n",
    "arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>A.4 Advanced ufunc Usage</h2>\n",
    "\n",
    "<p>While many NumPy users will only use the fast element-wise operations provided by the universal functions, a number of additional features occasionally can help you write more concise code without explicit loops.</p>\n",
    "\n",
    "<h3>ufunc Instance Methods</h3>\n",
    "\n",
    "<p>Each of NumPy’s binary ufuncs has special methods for performing certain kinds of special vectorized operations. These are summarized in <a href='#ufunc'>Table A.2: ufunc methods</a>, but I’ll give a few concrete examples to illustrate how they work.</p>\n",
    "\n",
    "<p><code>reduce</code> takes a single array and aggregates its values, optionally along an axis, by performing a sequence of binary operations. For example, an alternative way to sum elements in an array is to use <code>np.add.reduce</code>:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.arange(10)\n",
    "np.add.reduce(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>The starting value (for example, 0 for <code>add</code>) depends on the ufunc. If an axis is passed, the reduction is performed along that axis. This allows you to answer certain kinds of questions in a concise way. As a less mundane example, we can use <code>np.logical_and</code> to check whether the values in each row of an array are sorted:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_rng = np.random.default_rng(12346)  # for reproducibility\n",
    "arr = my_rng.standard_normal((5, 5))\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr[::2].sort(1) # sort a few rows\n",
    "arr[:, :-1] < arr[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.logical_and.reduce(arr[:, :-1] < arr[:, 1:], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Note that <code>logical_and</code>.reduce is equivalent to the <code>all</code> method.</p>\n",
    "\n",
    "<p>The <code>accumulate</code> ufunc method is related to <code>reduce</code>, like <code>cumsum</code> is related to <code>sum</code>. It produces an array of the same size with the intermediate “accumulated” values:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.arange(15).reshape((3, 5))\n",
    "np.add.accumulate(arr, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><code>outer</code> performs a pair-wise cross product between two arrays:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.arange(3).repeat([1, 2, 2])\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.multiply.outer(arr, np.arange(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>The output of <code>outer</code> will have a dimension that is the concatenation of the dimensions of the inputs:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = rng.standard_normal((3, 4)), rng.standard_normal(5)\n",
    "result = np.subtract.outer(x, y)\n",
    "result.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>The last method, <code>reduceat</code>, performs a “local reduce,” in essence an array “group by” operation in which slices of the array are aggregated together. It accepts a sequence of “bin edges” that indicate how to split and aggregate the values:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.arange(10)\n",
    "np.add.reduceat(arr, [0, 5, 8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>The results are the reductions (here, sums) performed over <code>arr[0:5]</code>, <code>arr[5:8]</code>, and <code>arr[8:]</code>. As with the other methods, you can pass an axis argument:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.multiply.outer(np.arange(4), np.arange(5))\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.add.reduceat(arr, [0, 2, 4], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>See <a href='#ufunc'>Table A.2: ufunc methods</a> for a partial listing of ufunc methods.</p>\n",
    "<table id='ufunc'>\n",
    "    <caption>Table A.2: ufunc methods</caption>\n",
    "    <tr>\n",
    "        <th>Method</th>\n",
    "        <th>Description</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><code>accumulate(x)</code></td>\n",
    "        <td>Aggregate values, preserving all partial aggregates.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><code>at(x, indieces, b=None)</code></td>\n",
    "        <td>Perform operation in place on <code>x</code> at the specified indices. The argument <code>b</code> is the second input to ufuncs that requires two array inputs.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><code>reduce(x)</code></td>\n",
    "        <td>Aggregate values by successive applications of the operation.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><code>reduceat(x, bins)</code></td>\n",
    "        <td>“Local” reduce or “group by”; reduce contiguous slices of data to produce an aggregated array.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><code>outer(x, y)</code></td>\n",
    "        <td>Apply operation to all pairs of elements in <code>x</code> and <code>y</code>; the resulting array has shape <code>x.shape + y.shape</code>.</td>\n",
    "    </tr>\n",
    "</table>\n",
    "<h3>Writing New ufunc in Python</h3>\n",
    "<p>There are a number of ways to create your own NumPy ufuncs. The most general is to use the NumPy C API, but that is beyond the scope of this book. In this section, we will look at pure Python ufuncs.</p>\n",
    "\n",
    "<p><code>numpy.frompyfunc</code> accepts a Python function along with a specification for the number of inputs and outputs. For example, a simple function that adds element-wise would be specified as:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_elements(x, y):\n",
    "    return x + y\n",
    "add_them = np.frompyfunc(add_elements, 2, 1)\n",
    "add_them(np.arange(8), np.arange(8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Functions created using <code>frompyfunc</code> always return arrays of Python objects, which can be inconvenient. Fortunately, there is an alternative (but slightly less feature rich) function, <code>numpy.vectorize</code>, that allows you to specify the output type:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_them = np.vectorize(add_elements, otypes=[np.float64])\n",
    "add_them(np.arange(8), np.arange(8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>These functions provide a way to create ufunc-like functions, but they are very slow because they require a Python function call to compute each element, which is a lot slower than NumPy’s C-based ufunc loops:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = rng.standard_normal(10000)\n",
    "%timeit add_them(arr, arr)\n",
    "%timeit np.add(arr, arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Later in this appendix we'll show how to create fast ufuncs in Python using the <a href=\"http://numba.pydata.org/\">Numba library</a>.\n",
    "    \n",
    "<h2>A.5 Structured and Record Arrays</h2>\n",
    "<span id='a_5'></span>\n",
    "<p>You may have noticed up until now that ndarray is a <em>homogeneous</em> data container; that is, it represents a block of memory in which each element takes up the same number of bytes, as determined by the data type. On the surface, this would appear to not allow you to represent heterogeneous or tabular data. A <em>structured</em> array is an ndarray in which each element can be thought of as representing a <em>struct</em> in C (hence the “structured” name) or a row in a SQL table with multiple named fields:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = [('x', np.float64), ('y', np.int32)]\n",
    "sarr = np.array([(1.5, 6), (np.pi, -2)], dtype=dtype)\n",
    "sarr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>There are several ways to specify a structured data type (see the online NumPy documentation). One typical way is as a list of tuples with <code>(field_name, field_data_type)</code>. Now, the elements of the array are tuple-like objects whose elements can be accessed like a dictionary:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "sarr[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "sarr[0]['y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>The field names are stored in the <code>dtype.names</code> attribute. When you access a field on the structured array, a strided view on the data is returned, thus copying nothing:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "sarr['x']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Nested Data Types and Multidimensional Fields</h3>\n",
    "\n",
    "<p>When specifying a structured data type, you can additionally pass a shape (as an int or tuple):</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = [('x', np.int64, 3), ('y', np.int32)]\n",
    "arr = np.zeros(4, dtype=dtype)\n",
    "arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>In this case, the <code>x</code> field now refers to an array of length 3 for each record:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr[0]['x']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Conveniently, accessing <code>arr['x']</code> then returns a two-dimensional array instead of a one-dimensional array as in prior examples:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr['x']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>This enables you to express more complicated, nested structures as a single block of memory in an array. You can also nest data types to make more complex structures. Here is an example:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = [('x', [('a', 'f8'), ('b', 'f4')]), ('y', np.int32)]\n",
    "data = np.array([((1, 2), 5), ((3, 4), 6)], dtype=dtype)\n",
    "data['x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['x']['a']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>pandas DataFrame does not support this feature in the same way, though it is similar to hierarchical indexing.</p>\n",
    "\n",
    "<h3>Why Use Structured Arrays?</h3>\n",
    "\n",
    "<p>Compared with a pandas DataFrame, NumPy structured arrays are a lower level tool. They provide a means to interpret a block of memory as a tabular structure with nested columns. Since each element in the array is represented in memory as a fixed number of bytes, structured arrays provide an efficient way of writing data to and from disk (including memory maps), transporting it over the network, and other such uses. The memory layout of each value in a structured array is based on the binary representation of struct data types in the C programming language.</p>\n",
    "\n",
    "<p>As another common use for structured arrays, writing data files as fixed-length record byte streams is a common way to serialize data in C and C++ code, which is sometimes found in legacy systems in industry. As long as the format of the file is known (the size of each record and the order, byte size, and data type of each element), the data can be read into memory with <code>np.fromfile</code>. Specialized uses like this are beyond the scope of this book, but it’s worth knowing that such things are possible.</p>\n",
    "\n",
    "<h2>A.6 More About Sorting</h2>\n",
    "\n",
    "<p>Like Python’s built-in list, the ndarray <code>sort</code> instance method is an in-place sort, meaning that the array contents are rearranged without producing a new array:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = rng.standard_normal(6)\n",
    "arr.sort()\n",
    "arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>When sorting arrays in place, remember that if the array is a view on a different ndarray, the original array will be modified:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = rng.standard_normal((3, 5))\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr[:, 1].sort()  # Sort second column values in place\n",
    "arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>On the other hand, <code>numpy.sort</code> creates a new, sorted copy of an array. Otherwise, it accepts the same arguments (such as <code>kind</code>) as ndarray's <code>sort</code> method:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = rng.standard_normal(5)\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sort(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>All of these sort methods take an axis argument for independently sorting the sections of data along the passed axis:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = rng.standard_normal((3, 5))\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr.sort(axis=1) # sort by row\n",
    "arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>You may notice that none of the sort methods have an option to sort in descending order. This is a problem in practice because array slicing produces views, thus not producing a copy or requiring any computational work. Many Python users are familiar with the “trick” that for a list of <code>values</code>, <code>values[::-1]</code> returns a list in reverse order. The same is true for ndarrays:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr[:, ::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Indirect Sorts: <code>argsort</code> and <code>lexsort</code></h3>\n",
    "\n",
    "<p>In data analysis you may need to reorder datasets by one or more keys. For example, a table of data about some students might need to be sorted by last name, then by first name. This is an example of an indirect sort, and if you’ve read the pandas-related chapters, you have already seen many higher-level examples. Given a key or keys (an array of values or multiple arrays of values), you wish to obtain an array of integer indices (I refer to them colloquially as indexers) that tells you how to reorder the data to be in sorted order. Two methods for this are <code>argsort</code> and <code>numpy.lexsort</code>. As an example:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = np.array([5, 0, 1, 3, 2])\n",
    "indexer = values.argsort()\n",
    "indexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "values[indexer]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>As a more complicated example, this code reorders a two-dimensional array by its first row:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = rng.standard_normal((3, 5))\n",
    "arr[0] = values\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr[:, arr[0].argsort()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><code>lexsort</code> is similar to <code>argsort</code>, but it performs an indirect <em>lexicographical</em> sort on multiple key arrays. Suppose we wanted to sort some data identified by first and last names:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_name = np.array(['Bob', 'Jane', 'Steve', 'Bill', 'Barbara'])\n",
    "last_name = np.array(['Jones', 'Arnold', 'Arnold', 'Jones', 'Walters'])\n",
    "sorter = np.lexsort((first_name, last_name))\n",
    "sorter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(zip(last_name[sorter], first_name[sorter]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><code>lexsort</code> can be a bit confusing the first time you use it, because the order in which the keys are used to order the data starts with the <em>first</em> array passed. Here, <code>last_name</code> was used before <code>first_name</code>.</p>\n",
    "\n",
    "<h3>Alternative Sort Algorithms</h3>\n",
    "\n",
    "<p>A <em>stable</em> sorting algorithm preserves the relative position of equal elements. This can be especially important in indirect sorts where the relative ordering is meaningful:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = np.array(['2:first', '2:second', '1:first', '1:second',\n",
    "                   '1:third'])\n",
    "key = np.array([2, 2, 1, 1, 1])\n",
    "indexer = key.argsort(kind='mergesort')\n",
    "indexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "values.take(indexer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>The only stable sort available is mergesort, which has guaranteed <code>O(n log n)</code> performance, but its performance is on average worse than the default quicksort method. See <a href='#array_sorting'>Table A.3: Array sorting methods</a> for a summary of available methods and their relative performance (and performance guarantees). This is not something that most users will ever have to think about, but it's useful to know that it’s there.</p>\n",
    "\n",
    "<table id=\"array_sorting\">\n",
    "    <caption>Table A.3: Array sorting methods</caption>\n",
    "    <tr>\n",
    "        <th>Kind</th>\n",
    "        <th>Speed</th>\n",
    "        <th>Stable</th>\n",
    "        <th>Work space</th>\n",
    "        <th>Worst case</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><code>'quicksort'</code></td>\n",
    "        <td>1</td>\n",
    "        <td>No</td>\n",
    "        <td>0</td>\n",
    "        <td><code>O(n^2)</code></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><code>'mergesort'</code></td>\n",
    "        <td>2</td>\n",
    "        <td>Yes</td>\n",
    "        <td><code>O(n / 2)</code></td>\n",
    "        <td><code>O(n log n)</code></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><code>3</code></td>\n",
    "        <td>3</td>\n",
    "        <td>No</td>\n",
    "        <td>O</td>\n",
    "        <td><code>O(n log n)</code></td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "<h3>Partially Sorting Arrays</h3>\n",
    "\n",
    "<p>One of the goals of sorting can be to determine the largest or smallest elements in an array. NumPy has fast methods, <code>numpy.partition</code> and <code>np.argpartition</code>, for partitioning an array around the <code>k</code>-th smallest element:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(12345)\n",
    "arr = rng.standard_normal(20)\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.partition(arr, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>After you call <code>partition(arr, 3)</code>, the first three elements in the result are the smallest three values in no particular order. <code>numpy.argpartition</code>, similar to <code>numpy.argsort</code>, returns the indices that rearrange the data into the equivalent order:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.argpartition(arr, 3)\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr.take(indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><code>numpy.searchsorted</code>: Finding Elements in a Sorted Array</h3>\n",
    "\n",
    "<p><code>searchsorted</code> is an array method that performs a binary search on a sorted array, returning the location in the array where the value would need to be inserted to maintain sortedness:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array([0, 1, 7, 12, 15])\n",
    "arr.searchsorted(9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>You can also pass an array of values to get an array of indices back:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr.searchsorted([0, 8, 11, 16])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>You might have noticed that <code>searchsorted</code> returned <code>0</code> for the <code>0</code> element. This is because the default behavior is to return the index at the left side of a group of equal values:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array([0, 0, 0, 1, 1, 1, 1])\n",
    "arr.searchsorted([0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr.searchsorted([0, 1], side='right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>As another application of <code>searchsorted</code>, suppose we had an array of values between 0 and 10,000, and a separate array of “bucket edges” that we wanted to use to bin the data:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.floor(rng.uniform(0, 10000, size=50))\n",
    "bins = np.array([0, 100, 1000, 5000, 10000])\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>To then get a labeling to which interval each data point belongs (where 1 would mean the bucket <code>[0, 100)</code>), we can simply use <code>searchsorted</code>:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = bins.searchsorted(data)\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>This, combined with pandas’s <code>groupby</code>, can be used to bin data:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(data).groupby(labels).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>A.7 Writing Fast NumPy Functions with Numba</h2>\n",
    "\n",
    "<p><a href='http://numba.pydata.org/'>Numba</a> is an open source project that creates fast functions for NumPy-like data using CPUs, GPUs, or other hardware. It uses the <a href='http://llvm.org/'>LLVM Project</a> to translate Python code into compiled machine code.</p>\n",
    "\n",
    "<p>To introduce Numba, let's consider a pure Python function that computes the expression <code>(x - y).mean()</code> using a <code>for</code> loop:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def mean_distance(x, y):\n",
    "    nx = len(x)\n",
    "    result = 0.0\n",
    "    count = 0\n",
    "    for i in range(nx):\n",
    "        result += x[i] - y[i]\n",
    "        count += 1\n",
    "    return result / count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>This function is slow:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = rng.standard_normal(10_000_000)\n",
    "y = rng.standard_normal(10_000_000)\n",
    "%timeit mean_distance(x, y)\n",
    "%timeit (x - y).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>The NumPy version is over 100 times faster. We can turn this function into a compiled Numba function using the <code>numba.jit</code> function:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numba as nb\n",
    "numba_mean_distance = nb.jit(mean_distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>We also could have written this as a decorator:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "@nb.jit\n",
    "def numba_mean_distance(x, y):\n",
    "    nx = len(x)\n",
    "    result = 0.0\n",
    "    count = 0\n",
    "    for i in range(nx):\n",
    "        result += x[i] - y[i]\n",
    "        count += 1\n",
    "    return result / count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>The resulting function is actually faster than the vectorized NumPy version:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit numba_mean_distance(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Numba cannot compile all pure Python code, but it supports a significant subset of Python that is most useful for writing numerical algorithms.</p>\n",
    "\n",
    "<p>Numba is a deep library, supporting different kinds of hardware, modes of compilation, and user extensions. It is also able to compile a substantial subset of the NumPy Python API without explicit <code>for</code> loops. Numba is able to recognize constructs that can be compiled to machine code, while substituting calls to the CPython API for functions that it does not know how to compile. Numba's <code>jit</code> function option, <code>nopython=True</code>, restricts allowed code to Python code that can be compiled to LLVM without any Python C API calls. <code>jit(nopython=True)</code> has a shorter alias, <code>numba.njit</code>.\n",
    "\n",
    "<p>In the previous example, we could have written:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import float64, njit\n",
    "\n",
    "@njit(float64(float64[:], float64[:]))\n",
    "def mean_distance(x, y):\n",
    "    return (x - y).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>I encourage you to learn more by reading the <a href='http://numba.pydata.org/'>online documentation for Numba</a>. The next section shows an example of creating custom NumPy ufunc objects.</p>\n",
    "\n",
    "<h3>Creating Custom <code>numpy.ufunc</code> Objects with Numba</h3>\n",
    "\n",
    "The <code>numba.vectorize</code> function creates compiled NumPy ufuncs, which behave like built-in ufuncs. Let's consider a Python implementation of <code>numpy.add</code>:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import vectorize\n",
    "\n",
    "@vectorize\n",
    "def nb_add(x, y):\n",
    "    return x + y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Now we have:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(10)\n",
    "nb_add(x, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_add.accumulate(x, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>A.8 Advanced Array Input and Output</h2>\n",
    "\n",
    "<p>In Ch 4: NumPy Basics: Arrays and Vectorized Computation, we became acquainted with <code>np.save</code> and <code>np.load</code> for storing arrays in binary format on disk. There are a number of additional options to consider for more sophisticated use. In particular, memory maps have the additional benefit of enabling you to do certain operations with datasets that do not fit into RAM.</p>\n",
    "\n",
    "<h3>Memory-Mapped Files</h3>\n",
    "\n",
    "<p>A <em>memory-mapped</em> file is a method for interacting with binary data on disk as though it is stored in an in-memory array. NumPy implements a <code>memmap</code> object that is ndarray-like, enabling small segments of a large file to be read and written without reading the whole array into memory. Additionally, a <code>memmap</code> has the same methods as an in-memory array and thus can be substituted into many algorithms where an ndarray would be expected.</p>\n",
    "\n",
    "<p>To create a new memory map, use the function <code>np.memmap</code> and pass a file path, data type, shape, and file mode:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmap = np.memmap('mymmap', dtype='float64', mode='w+',\n",
    "                 shape=(10000, 10000))\n",
    "mmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Slicing a <code>memmap</code> returns views on the data on disk:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "section = mmap[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>If you assign data to these, it will be buffered in memory, which means that the changes will not be immediately reflected in the on-disk file if you were to read the file in a different application. Any modifications can be synchronized to disk by calling <code>flush</code>:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "section[:] = rng.standard_normal((5, 10000))\n",
    "mmap.flush()\n",
    "mmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "del mmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Whenever a memory map falls out of scope and is garbage collected, any changes will be flushed to disk also. When <em>opening an existing memory map</em>, you still have to specify the data type and shape, as the file is only a block of binary data without any data type information, shape, or strides:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmap = np.memmap('mymmap', dtype='float64', shape=(10000, 10000))\n",
    "mmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Memory maps also work with structured or nested data types, as described in <a href='#a_5'>A.5 Structured and Record Arrays</a>.</p>\n",
    "<p>If you ran this example on your computer, you may want to delete the large file that we created above:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "%xdel mmap\n",
    "!rm mymmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>HDF5 and Other Array Storage Options</h3>\n",
    "\n",
    "<p>PyTables and h5py are two Python projects providing NumPy-friendly interfaces for storing array data in the efficient and compressible HDF5 format (HDF stands for <em>hierarchical data format</em>). You can safely store hundreds of gigabytes or even terabytes of data in HDF5 format. To learn more about using HDF5 with Python, I recommend reading the <a href='http://pandas.pydata.org/'>pandas online documentation</a>.</p>\n",
    "\n",
    "<h2>A.9 Performance Tips</h2>\n",
    "\n",
    "<p>Adapting data processing code to use NumPy generally makes things much faster, as array operations typically replace otherwise comparatively extremely slow pure Python loops. Here are some tips to help get the best performance out of the library:</p>\n",
    "<ul>\n",
    "    <li>Convert Python loops and conditional logic to array operations and Boolean array operations.</li>\n",
    "    <li>Use broadcasting whenever possible.</li>\n",
    "    <li>Use arrays views (slicing) to avoid copying data.</li>\n",
    "    <li>Utilize ufuncs and ufunc methods.</li>\n",
    "</ul>\n",
    "\n",
    "<p>If you can’t get the performance you require after exhausting the capabilities provided by NumPy alone, consider writing code in C, FORTRAN, or Cython. I use <a href='http://cython.org/'>Cython</a> frequently in my own work as a way to get C-like performance, often with much less development time.</p>\n",
    "\n",
    "<h3>The Importance of Contiguous Memory</h3>\n",
    "\n",
    "<p>While the full extent of this topic is a bit outside the scope of this book, in some applications the memory layout of an array can significantly affect the speed of computations. This is based partly on performance differences having to do with the cache hierarchy of the CPU; operations accessing contiguous blocks of memory (e.g., summing the rows of a C order array) will generally be the fastest because the memory subsystem will buffer the appropriate blocks of memory into the low latency L1 or L2 CPU caches. Also, certain code paths inside NumPy’s C codebase have been optimized for the contiguous case in which generic strided memory access can be avoided.</p>\n",
    "\n",
    "<p>To say that an array’s memory layout is contiguous means that the elements are stored in memory in the order that they appear in the array with respect to FORTRAN (column major) or C (row major) ordering. By default, NumPy arrays are created as C contiguous or just simply contiguous. A column major array, such as the transpose of a C-contiguous array, is thus said to be FORTRAN contiguous. These properties can be explicitly checked via the <code>flags</code> attribute on the ndarray:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_c = np.ones((100, 10000), order='C')\n",
    "arr_f = np.ones((100, 10000), order='F')\n",
    "arr_c.flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_f.flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_f.flags.f_contiguous"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>In this example, summing the rows of these arrays should, in theory, be faster for <code>arr_c</code> than <code>arr_f</code> since the rows are contiguous in memory. Here, I check using <code>%timeit</code> in IPython (these results may differ on your machine):</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit arr_c.sum(1)\n",
    "%timeit arr_f.sum(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>When you're looking to squeeze more performance out of NumPy, this is often a place to invest some effort. If you have an array that does not have the desired memory order, you can use <code>copy</code> and pass either <code>'C'</code> or <code>'F'</code>:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_f.copy('C').flags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>When constructing a view on an array, keep in mind that the result is not guaranteed to be contiguous:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_c[:50].flags.contiguous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_c[:, :50].flags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>If you ran this example on your computer, you may want to delete the large objects that we created above:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "%xdel arr_c\n",
    "%xdel arr_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = PREVIOUS_MAX_ROWS"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
